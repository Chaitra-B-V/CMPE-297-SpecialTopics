{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2+azHqGLcbFc6kLTQscAc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaitra-B-V/CMPE-297-SpecialTopics/blob/main/Assignment%206/Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAeQFnR3ZEIj"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Pretty printing helper\n",
        "def pretty_print(messages):\n",
        "    print(\"# Messages\")\n",
        "    for m in messages:\n",
        "        print(f\"{m.role}: {m.content[0].text.value}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def wait_on_run(run, thread):\n",
        "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
        "        run = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id,\n",
        "        )\n",
        "        time.sleep(0.5)\n",
        "    return run\n",
        "\n",
        "def display(obj):\n",
        "    print(obj)\n",
        "\n",
        "def show_json(obj):\n",
        "    display(json.loads(obj.model_dump_json()))\n",
        "\n",
        "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
        "\n",
        "client = OpenAI(api_key= openai_api_key)\n",
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a personal math tutor. Answer questions briefly, in a sentence or less.\",\n",
        "    model=\"gpt-4-1106-preview\",\n",
        ")\n",
        "show_json(assistant)\n",
        "\n",
        "MATH_ASSISTANT_ID = assistant.id  # or a hard-coded ID like \"asst-...\"\n",
        "\n",
        "def submit_message(assistant_id, thread, user_message):\n",
        "    client.beta.threads.messages.create(\n",
        "        thread_id=thread.id, role=\"user\", content=user_message\n",
        "    )\n",
        "    return client.beta.threads.runs.create(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=assistant_id,\n",
        "    )\n",
        "\n",
        "def get_response(thread):\n",
        "    return client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
        "\n",
        "def create_thread_and_run(user_input):\n",
        "    thread = client.beta.threads.create()\n",
        "    run = submit_message(MATH_ASSISTANT_ID, thread, user_input)\n",
        "    return thread, run\n",
        "\n",
        "# # Emulating concurrent user requests\n",
        "# thread1, run1 = create_thread_and_run(\n",
        "#     \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
        "# )\n",
        "# thread2, run2 = create_thread_and_run(\"Could you explain linear algebra to me?\")\n",
        "\n",
        "\n",
        "# # Wait for Run 1\n",
        "# run1 = wait_on_run(run1, thread1)\n",
        "# pretty_print(get_response(thread1))\n",
        "\n",
        "# # Wait for Run 2\n",
        "# run2 = wait_on_run(run2, thread2)\n",
        "# pretty_print(get_response(thread2))\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input(\"Ask your math question: \")\n",
        "\n",
        "    # Create thread and run\n",
        "    thread, run = create_thread_and_run(user_input)\n",
        "\n",
        "    # Wait for run to complete\n",
        "    run = wait_on_run(run, thread)\n",
        "\n",
        "    # Display responses\n",
        "    pretty_print(get_response(thread))\n",
        "\n",
        "    # Ask if user wants to continue\n",
        "    cont = input(\"Do you want to ask another question? (y/n): \")\n",
        "    if cont.lower() != \"y\":\n",
        "        break\n",
        "\n",
        "\n"
      ]
    }
  ]
}